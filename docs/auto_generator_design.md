# SGLang è‡ªåŠ¨é€‚é…é‡æ„è®¾è®¡æ–‡æ¡£


---

## èƒŒæ™¯ä¸ç›®æ ‡

å½“å‰ `auto_generator.py` çš„å®ç°å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
1. **ä»£ç ç”Ÿæˆæ–¹å¼éš¾ä»¥ç»´æŠ¤**ï¼šç”Ÿæˆ Python ä»£ç å­—ç¬¦ä¸²ï¼Œç±»å‹å®‰å…¨å·®ã€è°ƒè¯•å›°éš¾
2. **ç´§è€¦åˆçš„ Shape æå–é€»è¾‘**ï¼šç¡¬ç¼–ç çš„ `LAYER_PATTERNS`ï¼Œä¸æ˜“æ‰©å±•
3. **ç¼ºä¹ä¸­é—´æŠ½è±¡å±‚**ï¼šç›´æ¥ä» SGLang æ¨¡å‹è·³åˆ°ä»£ç ç”Ÿæˆï¼Œæ²¡æœ‰æ¸…æ™°çš„ IR å±‚

æœ¬è®¡åˆ’ç›®æ ‡æ˜¯å®ç°ä¸€ä¸ª**åˆ†å±‚ IR æ¶æ„**ï¼Œä½¿è‡ªåŠ¨é€‚é…æ›´åŠ ä¼˜é›…ã€å¯æ‰©å±•ã€æ˜“è°ƒè¯•ã€‚

---

## æ¶æ„è®¾è®¡

### æ ¸å¿ƒåˆ†å±‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SGLang Model (PyTorch nn.Module)                               â”‚
â”‚  - Qwen3MoeForCausalLM / DeepseekV3ForCausalLM / LlamaForCausalLMâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Parsing
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model IR (ä¸­é—´è¡¨ç¤ºå±‚)                                           â”‚
â”‚  - ComputationalGraph: æœ‰åºçš„ OpNode åˆ—è¡¨                        â”‚
â”‚  - OpNode: ç®—å­ç±»å‹ + å½¢çŠ¶ + å‚æ•° + å¹¶è¡Œç­–ç•¥                     â”‚
â”‚  - ä¸æ¡†æ¶æ— å…³ï¼Œå¯åºåˆ—åŒ–ã€å¯åˆ†æ                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ Transformation
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLMSim ModelArch (ç›´æ¥å®ä¾‹åŒ–)                                   â”‚
â”‚  - æ— éœ€ä»£ç ç”Ÿæˆï¼Œå†…å­˜ä¸­ç›´æ¥æ„å»º                                   â”‚
â”‚  - åŠ¨æ€åˆ›å»º OperatorMetadata å¹¶æ³¨å†Œåˆ° Arch                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®ä¼˜åŠ¿

1. **æ— éœ€ä»£ç ç”Ÿæˆ**ï¼šç›´æ¥åœ¨å†…å­˜ä¸­æ„å»º ModelArchï¼Œé¿å…å­—ç¬¦ä¸²æ‹¼æ¥å’Œæ–‡ä»¶IO
2. **å¯æ‰©å±•æ€§å¼º**ï¼šé€šè¿‡æ’ä»¶æœºåˆ¶æ³¨å†Œæ–°çš„ Layer Parserï¼Œç¬¦åˆå¼€é—­åŸåˆ™
3. **æ˜“äºè°ƒè¯•**ï¼šIR å±‚å¯ç‹¬ç«‹æ£€æŸ¥ã€å¯è§†åŒ–ã€éªŒè¯
4. **èŒè´£åˆ†ç¦»**ï¼šæ¯å±‚åªå…³å¿ƒè‡ªå·±çš„è½¬æ¢é€»è¾‘

---

## æ–‡ä»¶ç»“æ„

```
src/arch/models_arch/
â”œâ”€â”€ base_model_arch.py          # ä¿æŒä¸å˜
â”œâ”€â”€ model_arch.py               # ä¿æŒä¸å˜
â”œâ”€â”€ auto/
â”‚   â”œâ”€â”€ __init__.py             # å¯¼å‡º: auto_adapter, register_layer_parser
â”‚   â”œâ”€â”€ adapter.py              # ä¸»å…¥å£: SglangAutoAdapter
â”‚   â”œâ”€â”€ ir.py                   # IR å®šä¹‰: ComputationalGraph, OpNode
â”‚   â”œâ”€â”€ parser.py               # SGLang æ¨¡å‹è§£æå™¨
â”‚   â”œâ”€â”€ transformer.py          # IR â†’ ModelArch è½¬æ¢å™¨
â”‚   â””â”€â”€ layer_parsers/          # å±‚è§£æå™¨æ’ä»¶
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py             # BaseLayerParser æŠ½è±¡ç±»
â”‚       â”œâ”€â”€ linear.py           # Linear å±‚è§£æ (QKV, Row, Column)
â”‚       â”œâ”€â”€ attention.py        # Attention å±‚è§£æ
â”‚       â”œâ”€â”€ moe.py              # MoE å±‚è§£æ
â”‚       â”œâ”€â”€ norm.py             # Normalization å±‚è§£æ
â”‚       â””â”€â”€ registry.py         # è§£æå™¨æ³¨å†Œè¡¨
```

---

## æ ¸å¿ƒå®ç°ç»†èŠ‚

### 1. IR å±‚ (`ir.py`)

```python
@dataclass
class OpNode:
    """è®¡ç®—å›¾èŠ‚ç‚¹ - ä¸æ¡†æ¶æ— å…³çš„ä¸­é—´è¡¨ç¤º"""
    name: str
    op_type: str           # matmul, attention, transfer, norm
    input_shape: ShapeSpec # æ”¯æŒè¡¨è¾¾å¼å¦‚ "seq_len", "hidden_size"
    output_shape: ShapeSpec
    weight_shape: ShapeSpec
    dtype: DataType
    parallel_strategy: ParallelStrategy  # TP/EP åˆ‡åˆ†ç­–ç•¥
    num_layers: Union[int, str]  # å±‚æ•°æˆ–å¼•ç”¨å¦‚ "num_layers"
    extra_attrs: Dict[str, Any] = field(default_factory=dict)
    attention_type: Optional[str] = None  # mha, gqa, mla

@dataclass
class ComputationalGraph:
    """å®Œæ•´è®¡ç®—å›¾"""
    model_name: str
    model_type: str        # dense, moe, mla
    config: Dict[str, Any] # åŸå§‹é…ç½®å¼•ç”¨
    nodes: List[OpNode]
    kv_cache_type: str     # mha, gqa, mla

    # æ¨¡å‹ç‰¹æ€§æ ‡å¿—
    has_moe: bool = False
    has_mla: bool = False
    has_dense_layers: bool = False
    first_k_dense_replace: int = 0

    def get_nodes_by_type(self, op_type: str) -> List[OpNode]: ...
    def get_attention_nodes(self) -> List[OpNode]: ...
    def get_matmul_nodes(self) -> List[OpNode]: ...
    def get_transfer_nodes(self) -> List[OpNode]: ...
    def get_node_by_name(self, name: str) -> Optional[OpNode]: ...
    def validate(self) -> List[str]: ...
    def to_dict(self) -> Dict[str, Any]: ...
    @staticmethod
    def from_dict(data: Dict[str, Any]) -> "ComputationalGraph": ...

@dataclass
class ShapeSpec:
    """å½¢çŠ¶è§„èŒƒï¼Œæ”¯æŒå…·ä½“å€¼å’Œç¬¦å·è¡¨è¾¾å¼"""
    m: Union[int, str] = 0
    n: Union[int, str] = 0

    @property
    def is_symbolic(self) -> bool: ...
    def resolve(self, context: Dict[str, Any]) -> Tuple[int, int]: ...

@dataclass
class ParallelStrategy:
    """å¹¶è¡ŒåŒ–ç­–ç•¥"""
    tp_dim: Optional[int] = None  # 0=row-wise, 1=column-wise
    ep_size: int = 1
    replicated: bool = False
```

### 2. è§£æå™¨æ’ä»¶ç³»ç»Ÿ (`layer_parsers/`)

```python
# base.py
class BaseLayerParser(ABC):
    """å±‚è§£æå™¨åŸºç±»"""

    @property
    @abstractmethod
    def layer_types(self) -> List[str]:
        """è¿”å›æ”¯æŒçš„ PyTorch å±‚ç±»å‹ååˆ—è¡¨"""
        pass

    @abstractmethod
    def parse(self, name: str, module: nn.Module, config: Any) -> Optional[OpNode]:
        """è§£æå±‚å¹¶è¿”å› OpNodeï¼Œè¿”å› None è¡¨ç¤ºè·³è¿‡"""
        pass

    def can_parse(self, module: nn.Module) -> bool: ...

# registry.py
_layer_parsers: Dict[str, BaseLayerParser] = {}

def register_layer_parser(*layer_types: str):
    """è£…é¥°å™¨ï¼šæ³¨å†Œå±‚è§£æå™¨"""
    def decorator(parser_class: Type[BaseLayerParser]):
        parser = parser_class()
        for lt in layer_types:
            _layer_parsers[lt] = parser
        return parser_class
    return decorator

def get_parser(layer_type: str) -> Optional[BaseLayerParser]: ...
def list_registered_parsers() -> Dict[str, str]: ...
def unregister_parser(layer_type: str) -> bool: ...
```

### 3. å…·ä½“è§£æå™¨å®ç°

#### 3.1 Linear å±‚ (`layer_parsers/linear.py`)

```python
@register_layer_parser("QKVParallelLinear", "QKVSepParallelLinear")
class QKVLinearParser(BaseLayerParser):
    """è§£æ QKV æŠ•å½±å±‚"""

    @property
    def layer_types(self) -> List[str]:
        return ["QKVParallelLinear", "QKVSepParallelLinear"]

    def parse(self, name: str, module: nn.Module, config: Any) -> OpNode:
        # å¤„ç† MLA é£æ ¼çš„åˆ†ç¦» QKV
        if "QKVSepParallelLinear" in type(module).__name__:
            return self._parse_mla_qkv(name, module, config)

        return OpNode(
            name=name,
            op_type="matmul",
            input_shape=ShapeSpec("seq_len", "hidden_size"),
            output_shape=ShapeSpec(
                "seq_len", "(num_heads_per_rank + kv_heads_per_rank * 2) * head_dim"
            ),
            weight_shape=ShapeSpec(
                "hidden_size", "(num_heads_per_rank + kv_heads_per_rank * 2) * head_dim"
            ),
            dtype=DataType.BF16,
            parallel_strategy=ParallelStrategy(tp_dim=1),
            num_layers="num_layers",
            extra_attrs={"is_attention": True, "is_qkv": True},
        )

@register_layer_parser("RowParallelLinear")
class RowLinearParser(BaseLayerParser):
    """è§£æ RowParallelLinear (é€šå¸¸æ˜¯ o_proj, down_proj)"""
    ...

@register_layer_parser("ColumnParallelLinear")
class ColumnLinearParser(BaseLayerParser):
    """è§£æ ColumnParallelLinear (é€šå¸¸æ˜¯ gate_up_proj)"""
    ...

@register_layer_parser("ReplicatedLinear")
class ReplicatedLinearParser(BaseLayerParser):
    """è§£æ ReplicatedLinear (é€šå¸¸æ˜¯ MoE gate)"""
    ...
```

#### 3.2 Attention å±‚ (`layer_parsers/attention.py`)

```python
@register_layer_parser("RadixAttention")
class RadixAttentionParser(BaseLayerParser):
    """è§£æ RadixAttention (æ ‡å‡† MHA/GQA)"""
    ...

@register_layer_parser("MLAAttention")
class MLAAttentionParser(BaseLayerParser):
    """è§£æ MLAAttention (DeepSeek é£æ ¼)"""
    ...

@register_layer_parser("LlamaAttention", "Qwen2Attention")
class StandardAttentionParser(BaseLayerParser):
    """è§£ææ ‡å‡† Attention (Llama, Qwen2, Qwen3)"""
    ...
```

#### 3.3 MoE å±‚ (`layer_parsers/moe.py`)

```python
@register_layer_parser("FusedMoE")
class FusedMoEParser(BaseLayerParser):
    """è§£æ FusedMoE"""
    ...

@register_layer_parser("Qwen3MoeSparseMoeBlock", "DeepseekV3MoE")
class MoEBlockParser(BaseLayerParser):
    """è§£æ MoE Block (å¤åˆå±‚ï¼Œè¿”å› None å¤„ç†å­å±‚)"""
    ...

@register_layer_parser("MoEGate", "TopKGate")
class MoEGateParser(BaseLayerParser):
    """è§£æ MoE Gate"""
    ...
```

#### 3.4 Normalization å±‚ (`layer_parsers/norm.py`)

```python
@register_layer_parser("RMSNorm", "LayerNorm", "FusedRMSNorm")
class NormParser(BaseLayerParser):
    """è§£æ Normalization å±‚ (è·³è¿‡ï¼Œä¸ç”Ÿæˆç®—å­)"""

    def parse(self, name: str, module: nn.Module, config: Any) -> Optional[OpNode]:
        return None  # è·³è¿‡
```

### 4. ä¸»é€‚é…å™¨ (`adapter.py`)

```python
class SglangAutoAdapter:
    """SGLang æ¨¡å‹è‡ªåŠ¨é€‚é…å™¨ä¸»å…¥å£"""

    def __init__(self, model_class: Type, config: Any):
        self.model_class = model_class
        self.config = config
        self._ir_graph: Optional[ComputationalGraph] = None
        self._model_arch: Optional[BaseModelArch] = None

    @property
    def ir_graph(self) -> Optional[ComputationalGraph]: ...

    @property
    def model_arch(self) -> Optional[BaseModelArch]: ...

    def parse(self) -> ComputationalGraph:
        """ç¬¬ä¸€æ­¥ï¼šè§£æ SGLang æ¨¡å‹ä¸º IR"""
        parser = ModelParser(self.config)
        self._ir_graph = parser.parse(self.model_class)
        return self._ir_graph

    def transform(self, schedule_config: ScheduleConfig) -> BaseModelArch:
        """ç¬¬äºŒæ­¥ï¼šå°† IR è½¬æ¢ä¸º ModelArch"""
        if self._ir_graph is None:
            self.parse()

        transformer = IRToModelArchTransformer(self._ir_graph, schedule_config)
        self._model_arch = transformer.transform()
        return self._model_arch

    def adapt(self, schedule_config: ScheduleConfig) -> BaseModelArch:
        """ä¸€é”®é€‚é…ï¼šparse + transform"""
        return self.transform(schedule_config)

    def get_ir_summary(self) -> dict:
        """è·å– IR æ‘˜è¦ç”¨äºè°ƒè¯•"""
        ...


def auto_adapter(
    model_class: Type, config: Any, schedule_config: ScheduleConfig
) -> BaseModelArch:
    """ä¾¿æ·å‡½æ•°"""
    adapter = SglangAutoAdapter(model_class, config)
    return adapter.adapt(schedule_config)


def parse_model(model_class: Type, config: Any) -> ComputationalGraph:
    """ä»…è§£æåˆ° IRï¼Œä¸è½¬æ¢ä¸º ModelArch"""
    adapter = SglangAutoAdapter(model_class, config)
    return adapter.parse()
```

### 5. SGLang æ¨¡å‹è§£æå™¨ (`parser.py`)

```python
class ModelParser:
    """è§£æ SGLang æ¨¡å‹å¹¶æå– ComputationalGraph IR"""

    SKIP_LAYER_TYPES: Set[str] = {
        "Embedding",
        "RotaryEmbedding",
        "LlamaRotaryEmbedding",
        "Qwen2RotaryEmbedding",
    }

    def __init__(self, config: Any):
        self.config = config
        self._unsupported_layers: List[Dict[str, str]] = []

    def parse(self, model_class: Type) -> ComputationalGraph:
        """è§£ææ¨¡å‹ç±»å¹¶è¿”å› ComputationalGraph"""
        with mock_sglang_environment():
            model = self._instantiate_model(model_class)

        graph = self._create_graph(model_class)
        self._traverse_model(model, graph)
        return graph

    def _infer_model_type(self) -> str: ...
    def _has_moe(self) -> bool: ...
    def _has_mla(self) -> bool: ...
    def _infer_kv_cache_type(self) -> str: ...
    def _traverse_model(self, model: Any, graph: ComputationalGraph): ...
    def _parse_layer(self, name: str, module: nn.Module) -> Optional[OpNode]: ...


@contextmanager
def mock_sglang_environment():
    """æ¨¡æ‹Ÿ SGLang ç¯å¢ƒä»¥ç»•è¿‡åˆ†å¸ƒå¼ä¾èµ–"""
    mock_modules = create_mock_environment()
    # æ›¿æ¢ sys.modules
    ...
    try:
        yield
    finally:
        # æ¢å¤åŸå§‹æ¨¡å—
        ...
```

### 6. IR åˆ° ModelArch è½¬æ¢å™¨ (`transformer.py`)

```python
class IRToModelArchTransformer:
    """å°† IR è®¡ç®—å›¾è½¬æ¢ä¸º LLMSim ModelArch"""

    def __init__(self, ir_graph: ComputationalGraph, schedule_config: ScheduleConfig):
        self.ir_graph = ir_graph
        self.schedule_config = schedule_config
        self._shape_context: Dict[str, Any] = {}

    def transform(self) -> BaseModelArch:
        """è½¬æ¢å…¥å£"""
        model_config = self._create_model_config()
        arch = create_model_arch(model_config, self.schedule_config)

        self._build_shape_context(model_config)
        self._build_operators(arch)

        return arch

    def _build_operators(self, arch: BaseModelArch):
        """ä» IR èŠ‚ç‚¹æ„å»ºç®—å­"""
        # åˆ†ç»„å¤„ç†ä¸åŒç±»å‹çš„èŠ‚ç‚¹
        attention_proj_nodes = []
        attention_core_nodes = []
        ffn_nodes = []
        moe_nodes = []
        transfer_nodes = []

        for node in self.ir_graph.nodes:
            if node.op_type == "matmul":
                if node.extra_attrs.get("is_attention"):
                    attention_proj_nodes.append(node)
                elif node.extra_attrs.get("is_moe"):
                    moe_nodes.append(node)
                else:
                    ffn_nodes.append(node)
            elif node.op_type == "attention":
                attention_core_nodes.append(node)
            elif node.op_type == "transfer":
                transfer_nodes.append(node)

        # æ„å»ºå„ç±»ç®—å­
        self._build_attention_operators(arch, attention_proj_nodes, attention_core_nodes)
        self._build_ffn_operators(arch, ffn_nodes)
        self._build_moe_operators(arch, moe_nodes)
        self._build_transfer_operators(arch)

    def _resolve_shape(self, shape_spec: ShapeSpec) -> tuple:
        """è§£æ ShapeSpec åˆ°å…·ä½“ç»´åº¦"""
        return shape_spec.resolve(self._shape_context)
```

---

## æ‰©å±•æœºåˆ¶

### æ·»åŠ æ–°å±‚ç±»å‹æ”¯æŒ

```python
# 1. åˆ›å»ºè§£æå™¨
from src.arch.models_arch.auto.layer_parsers import register_layer_parser, BaseLayerParser

@register_layer_parser("FlashAttention", "PagedAttention")
class FlashAttentionParser(BaseLayerParser):
    @property
    def layer_types(self) -> List[str]:
        return ["FlashAttention", "PagedAttention"]

    def parse(self, name: str, module: nn.Module, config: Any) -> OpNode:
        return OpNode(
            name=name,
            op_type="attention",
            # ... å½¢çŠ¶è®¡ç®—
        )

# 2. è‡ªåŠ¨æ³¨å†Œï¼Œæ— éœ€ä¿®æ”¹å…¶ä»–ä»£ç 
```

---

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ç”¨æ³•

```python
# ä½¿ç”¨æ–°çš„è‡ªåŠ¨é€‚é… API
from src.arch.models_arch.auto import auto_adapter
from src.arch.config import ScheduleConfig

# 1. ä» HuggingFace åŠ è½½é…ç½®
from transformers import AutoConfig
config = AutoConfig.from_pretrained("Qwen/Qwen3-30B-A3B")

# 2. å¯¼å…¥ SGLang æ¨¡å‹ç±»
from sglang.srt.models.qwen3_moe import Qwen3MoeForCausalLM

# 3. åˆ›å»ºè°ƒåº¦é…ç½®
schedule_config = ScheduleConfig(
    mode="extend",
    tp_size=4,
    dp_size=2,
    ep_size=8,
)

# 4. ä¸€é”®é€‚é…
model_arch = auto_adapter(Qwen3MoeForCausalLM, config, schedule_config)

# 5. ç›´æ¥ä½¿ç”¨è¿›è¡Œæ€§èƒ½è®¡ç®—
from src.arch.perf_calculator import PerformanceCalculator
calculator = PerformanceCalculator(hardware_config)
result = calculator.calculate_model_performance(model_arch)
```

### åˆ†æ­¥ç”¨æ³•ï¼ˆç”¨äºè°ƒè¯•ï¼‰

```python
from src.arch.models_arch.auto import SglangAutoAdapter

# åˆ›å»ºé€‚é…å™¨
adapter = SglangAutoAdapter(Qwen3MoeForCausalLM, config)

# ç¬¬ä¸€æ­¥ï¼šè§£æåˆ° IRï¼ˆå¯æ£€æŸ¥ä¸­é—´ç»“æœï¼‰
ir_graph = adapter.parse()
print(f"Model has {len(ir_graph.nodes)} operators")
print(f"Model type: {ir_graph.model_type}")

# è·å– IR æ‘˜è¦
summary = adapter.get_ir_summary()
print(f"Matmul nodes: {summary['matmul_nodes']}")
print(f"Attention nodes: {summary['attention_nodes']}")

# ç¬¬äºŒæ­¥ï¼šè½¬æ¢ä¸º ModelArch
model_arch = adapter.transform(schedule_config)
```

### IR åºåˆ—åŒ–ï¼ˆç”¨äºç¼“å­˜/è°ƒè¯•ï¼‰

```python
from src.arch.models_arch.auto import parse_model
import json

# è§£æåˆ° IR
ir_graph = parse_model(Qwen3MoeForCausalLM, config)

# ä¿å­˜åˆ°æ–‡ä»¶
with open("model_ir.json", "w") as f:
    json.dump(ir_graph.to_dict(), f, indent=2)

# ä»æ–‡ä»¶åŠ è½½
from src.arch.models_arch.auto.ir import ComputationalGraph
with open("model_ir.json", "r") as f:
    data = json.load(f)
restored_graph = ComputationalGraph.from_dict(data)
```

---

## æµ‹è¯•

æµ‹è¯•æ–‡ä»¶ä½äº `tests/test_auto_adapter.py`ï¼ŒåŒ…å«ï¼š

- **28 ä¸ªé€šè¿‡æµ‹è¯•**ï¼šè¦†ç›– IRã€è§£æå™¨æ³¨å†Œè¡¨ã€æ•°æ®ç±»å‹ã€Mock ç¯å¢ƒã€é€‚é…å™¨ API
- **11 ä¸ªè·³è¿‡æµ‹è¯•**ï¼šéœ€è¦ PyTorchï¼ˆModelParser ç›¸å…³ï¼‰

è¿è¡Œæµ‹è¯•ï¼š
```bash
pytest tests/test_auto_adapter.py -v
```

---

## å…³é”®æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `src/arch/models_arch/auto/__init__.py` | âœ… å·²å®ç° | åŒ…å…¥å£ |
| `src/arch/models_arch/auto/ir.py` | âœ… å·²å®ç° | IR å®šä¹‰ |
| `src/arch/models_arch/auto/parser.py` | âœ… å·²å®ç° | SGLang æ¨¡å‹è§£æ |
| `src/arch/models_arch/auto/transformer.py` | âœ… å·²å®ç° | IR â†’ ModelArch |
| `src/arch/models_arch/auto/adapter.py` | âœ… å·²å®ç° | ä¸»é€‚é…å™¨ |
| `src/arch/models_arch/auto/layer_parsers/base.py` | âœ… å·²å®ç° | è§£æå™¨åŸºç±» |
| `src/arch/models_arch/auto/layer_parsers/registry.py` | âœ… å·²å®ç° | è§£æå™¨æ³¨å†Œè¡¨ |
| `src/arch/models_arch/auto/layer_parsers/linear.py` | âœ… å·²å®ç° | Linear å±‚è§£æ |
| `src/arch/models_arch/auto/layer_parsers/attention.py` | âœ… å·²å®ç° | Attention å±‚è§£æ |
| `src/arch/models_arch/auto/layer_parsers/moe.py` | âœ… å·²å®ç° | MoE å±‚è§£æ |
| `src/arch/models_arch/auto/layer_parsers/norm.py` | âœ… å·²å®ç° | Normalization å±‚è§£æ |
| `src/arch/models_arch/auto_generator.py` | ğŸ“ ä¿ç•™ | æ ‡è®° deprecated |
| `examples/generate_from_sglang.py` | ğŸ“ ä¿ç•™ | æ ‡è®° deprecated |
| `tests/test_auto_adapter.py` | âœ… å·²å®ç° | å•å…ƒæµ‹è¯• |

---

## å·²æ³¨å†Œè§£æå™¨åˆ—è¡¨

å½“å‰å…± **19 ä¸ª** å·²æ³¨å†Œè§£æå™¨ï¼š

| å±‚ç±»å‹ | è§£æå™¨ç±» |
|--------|----------|
| QKVParallelLinear, QKVSepParallelLinear | QKVLinearParser |
| RowParallelLinear | RowLinearParser |
| ColumnParallelLinear | ColumnLinearParser |
| ReplicatedLinear | ReplicatedLinearParser |
| MergedColumnParallelLinear | MergedColumnLinearParser |
| RadixAttention | RadixAttentionParser |
| MLAAttention | MLAAttentionParser |
| LlamaAttention, Qwen2Attention | StandardAttentionParser |
| FusedMoE | FusedMoEParser |
| Qwen3MoeSparseMoeBlock | Qwen3MoEBlockParser |
| DeepseekV3MoE | DeepSeekV3MoEParser |
| MoEGate, TopKGate | MoEGateParser |
| Expert | ExpertParser |
| RMSNorm, LayerNorm, FusedRMSNorm | NormParser |
